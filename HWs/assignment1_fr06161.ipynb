{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPIRcDn2BrIW5ZU0d6MbmKi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fizza-Rubab/CS432-GPU/blob/main/HWs/assignment1_fr06161.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 1\n",
        "## Fizza Rubab\n",
        "\n",
        "### Question 1\n",
        "The first task asks you to write CUDA code to initialize a random array of 1000000 elements.\n",
        "Provide the following:\n",
        "\n",
        "#### Part (1)\n",
        "Share the amount of time it takes to populate data in the array on the CPU. Use any\n",
        "timing function like clock() or hiresolution counters to note the amount of time it takes to\n",
        "generate data on the CPU. (+20)\n"
      ],
      "metadata": {
        "id": "uY-JRkWTD8lf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opvATcR0D7JO",
        "outputId": "2781def8-a346-4dee-a237-84b66d060f65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-8wxps8_n\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-8wxps8_n\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4304 sha256=9e97d9052f5d73573552a018d4f63d57627fd9f671eeba5cfa20b9040f1042f7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-74z8kcu7/wheels/f3/08/cc/e2b5b0e1c92df07dbb50a6f024a68ce090f5e7b2316b41756d\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n",
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc_plugin\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwyRZzo-EzSJ",
        "outputId": "b7458791-a4c4-406d-b7a9-e9a496685fc9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jan 26 15:06:14 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   64C    P0    29W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <bits/stdc++.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "inline cudaError_t checkCudaErr(cudaError_t err, const char* msg) {\n",
        "  if (err != cudaSuccess) {\n",
        "    fprintf(stderr, \"CUDA Runtime error at %s: %s\\n\", msg, cudaGetErrorString(err));\n",
        "  }\n",
        "  return err;\n",
        "}\n",
        " \n",
        "\n",
        "__global__ void MyKernel(int* data) \n",
        "{\n",
        "    \n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  const int N = 1000000;\n",
        "  clock_t start, end;\n",
        "  start = clock();\n",
        "  int array[N];\n",
        "  for (int i=0; i<N; i++)\n",
        "    array[i] = rand();\n",
        "  end = clock();\n",
        "  double time_elapsed = double(end - start) / double(CLOCKS_PER_SEC);\n",
        "  printf(\"Time taken to generate a 1000000 element random array is %f seconds.\\n\", time_elapsed);\n",
        "  printf(\"Displaying first 10 elements for verification:\\n\");\n",
        "  for (int i = 0; i < 10; i++)\n",
        "      printf(\"%d\\n\", array[i]);\n",
        "  return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTNEgsV4E5KT",
        "outputId": "604ad249-228c-4ded-b733-66b7cc74a152"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken to generate a 1000000 element random array is 0.008089 seconds.\n",
            "Displaying first 10 elements for verification:\n",
            "1804289383\n",
            "846930886\n",
            "1681692777\n",
            "1714636915\n",
            "1957747793\n",
            "424238335\n",
            "719885386\n",
            "1649760492\n",
            "596516649\n",
            "1189641421\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### References\n",
        "1. https://www.geeksforgeeks.org/measure-execution-time-with-high-precision-in-c-c/\n",
        "2. https://www.tutorialspoint.com/c_standard_library/c_function_rand.htm"
      ],
      "metadata": {
        "id": "LASNvYwIH8Q6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part(2)\n",
        "Find a way to do the random data initialization of the array on the GPU. Do not just\n",
        "copy data from CPU array to GPU. Instead, you should use any library like cuRand but\n",
        "you should provide relevant references. Note the time it takes to run the kernel using the\n",
        "CUDA event API to calculate the amount of time needed by the GPU. (+20)"
      ],
      "metadata": {
        "id": "9Pa_6swVIz0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/q1part2.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#include <curand_kernel.h>\n",
        "inline cudaError_t checkCudaErr(cudaError_t err, const char* msg) {\n",
        "  if (err != cudaSuccess) {\n",
        "    fprintf(stderr, \"CUDA Runtime error at %s: %s\\n\", msg, cudaGetErrorString(err));\n",
        "  }\n",
        "  return err;\n",
        "}\n",
        "\n",
        "__global__ void device_api_kernel(curandState *states, int *result, int N)\n",
        "{\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    curandState *state = states + i;\n",
        "    curand_init(9384, i, 0, state);\n",
        "    result[i] = curand(state);\n",
        "}\n",
        "\n",
        "\n",
        "int main(int argc, char **argv)\n",
        "{\n",
        "    int N = 1000000;\n",
        "    curandState *states = NULL;\n",
        "    int *d_data, *h_data;\n",
        "\t  int threads_per_block =  64;\n",
        "\t  int blocks_per_grid = ceil(N/threads_per_block + 1);\n",
        "    cudaMalloc((void **)&d_data, sizeof(int) * N);\n",
        "    cudaMalloc((void **)&states, sizeof(curandState)*threads_per_block * blocks_per_grid);\n",
        "    h_data = (int *)malloc(sizeof(int) * N);\n",
        "\n",
        "    cudaEvent_t start, stop;\n",
        "    float elapsedTime;\n",
        "\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventRecord(start,0);\n",
        "\n",
        "\n",
        "    device_api_kernel<<<blocks_per_grid, threads_per_block>>>(states, d_data, N);\n",
        "\n",
        "\n",
        "    cudaEventCreate(&stop);\n",
        "    cudaEventRecord(stop,0);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    cudaEventElapsedTime(&elapsedTime, start,stop);\n",
        "    printf(\"Elapsed time for generating random numbers: %fs\\n\" ,elapsedTime/1000);\n",
        "\n",
        "    checkCudaErr(cudaMemcpy(h_data, d_data, sizeof(int) * N, cudaMemcpyDeviceToHost), \"memcopy\");\n",
        "    printf(\"Displaying first 10 random numbers from array of 1000000 elements\\n\");\n",
        "    for (int i = 0; i < 10; i++)\n",
        "        printf(\"%d\\n\", h_data[i]);\n",
        "    free(h_data);\n",
        "    cudaFree(d_data);\n",
        "    cudaFree(states);\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuMdwHYGKw4B",
        "outputId": "01f01a32-7d4b-4bbb-b058-3092c8fab68d"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/q1part2.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc /content/q1part2.cu -lcurand -o q1part2 && ./q1part2"
      ],
      "metadata": {
        "id": "5V5NuQJ9TXX-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cb28392-7fe2-442c-b735-684040802e7f"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time for generating random numbers: 0.044527s\n",
            "Displaying first 10 random numbers from array of 1000000 elements\n",
            "-456389480\n",
            "-1997568819\n",
            "-948239084\n",
            "1671272147\n",
            "713009428\n",
            "1077169352\n",
            "-1363832762\n",
            "661140645\n",
            "387525661\n",
            "436233125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part(3)\n",
        "Copy the random array data generated on the GPU from the GPU to the CPU using\n",
        "cudaMemcpy. Note the amount of time it takes to move the data from GPU to the CPU.\n",
        "(+10)"
      ],
      "metadata": {
        "id": "bEvxGi0EW71C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/q1part3.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#include <curand_kernel.h>\n",
        "inline cudaError_t checkCudaErr(cudaError_t err, const char* msg) {\n",
        "  if (err != cudaSuccess) {\n",
        "    fprintf(stderr, \"CUDA Runtime error at %s: %s\\n\", msg, cudaGetErrorString(err));\n",
        "  }\n",
        "  return err;\n",
        "}\n",
        "\n",
        "__global__ void device_api_kernel(curandState *states, int *result, int N)\n",
        "{\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    curandState *state = states + i;\n",
        "    curand_init(9384, i, 0, state);\n",
        "    result[i] = curand(state);\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "int main(int argc, char **argv)\n",
        "{\n",
        "    int N = 1000000;\n",
        "    curandState *states = NULL;\n",
        "    int *d_data, *h_data;\n",
        "\t  int threads_per_block =  64;\n",
        "\t  int blocks_per_grid = ceilf(N/threads_per_block + 1);\n",
        "    cudaMalloc((void **)&d_data, sizeof(int) * N);\n",
        "    cudaMalloc((void **)&states, sizeof(curandState)*threads_per_block * blocks_per_grid);\n",
        "    h_data = (int *)malloc(sizeof(int) * N);\n",
        "\n",
        "    device_api_kernel<<<blocks_per_grid, threads_per_block>>>(states, d_data, N);\n",
        "    cudaEvent_t start, stop;\n",
        "    float elapsedTime;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventRecord(start,0);\n",
        "    checkCudaErr(cudaMemcpy(h_data, d_data, sizeof(int) * N, cudaMemcpyDeviceToHost), \"memcopy\");\n",
        "    cudaEventCreate(&stop);\n",
        "    cudaEventRecord(stop,0);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    cudaEventElapsedTime(&elapsedTime, start,stop);\n",
        "    printf(\"Elapsed time for Copying data from device to host: %fs\\n\" ,elapsedTime/1000);\n",
        "    printf(\"Displaying first 10 random numbers from array of 1000000 elements\\n\");\n",
        "    for (int i = 0; i < 10; i++)\n",
        "        printf(\"%d\\n\", h_data[i]);\n",
        "    free(h_data);\n",
        "    cudaFree(d_data);\n",
        "    cudaFree(states);\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0j-x7tLLOd2",
        "outputId": "425145fc-1e11-4e2b-ed08-504419ff57ba"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/q1part3.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc /content/q1part3.cu -lcurand -o q1part3 && ./q1part3"
      ],
      "metadata": {
        "id": "DpneP3JJMsY6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b48f51a-d4f7-471c-c2c0-268ea525e866"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA Runtime error at memcopy: no CUDA-capable device is detected\n",
            "Elapsed time for Copying data from device to host: 0.000000s\n",
            "Displaying first 10 random numbers from array of 1000000 elements\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2\n",
        "Write CUDA code to calculate the sum of 1000 elements array and output the sum. Calculate\n",
        "the total time for doing the calculation on the CPU as well as on the GPU. Use an appropriate\n",
        "execution configuration when you launch your kernel. Share the following information from your\n",
        "solution.\n",
        "\n",
        "1. Code compiles and outputs as expected both on CPU and GPU. (+10)\n",
        "2. Plot your results in a graph and show both your results (CPU/GPU) against different\n",
        "dataset sizes (1000,10000,100000) and different execution configurations (+30)\n",
        "3. Do proper error handling in your code so any CUDA error should be reported to the user.\n",
        "(+10)\n",
        "\n"
      ],
      "metadata": {
        "id": "ypGqX5-AXAYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/q2part1.cu\n",
        "#include <stdio.h>\n",
        "#include <bits/stdc++.h>\n",
        "\n",
        "inline cudaError_t checkCudaErr(cudaError_t err, const char* msg) {\n",
        "  if (err != cudaSuccess) {\n",
        "    fprintf(stderr, \"CUDA Runtime error at %s: %s\\n\", msg, cudaGetErrorString(err));\n",
        "  }\n",
        "  return err;\n",
        "}\n",
        " \n",
        "\n",
        "__global__ void InitData(int* data, int* d_sum, int N) \n",
        "{\n",
        "\n",
        "    // Since only one thread, threadIdx.x = 0, just use i = 0\n",
        "    for (int i=threadIdx.x;i<N;i++)\n",
        "      *d_sum+=data[i]; //Store sum\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  const int N = 100;  \n",
        "\n",
        "  int* h_data = (int*)calloc(N, sizeof(int));\n",
        "  for (int j=0;j<N;j++)\n",
        "    h_data[j]=1;\n",
        "  \n",
        "  clock_t start, end;\n",
        "  start = clock();\n",
        "  int h_sum = 0;\n",
        "  for (int j=0;j<N;j++)\n",
        "    h_sum+=h_data[j];\n",
        "  end = clock();\n",
        "  double time_elapsed = double(end - start) / double(CLOCKS_PER_SEC);\n",
        "  printf(\"Sum of the array computed at CPU is %d\\nTotal Time taken on CPU: %fs\\n\", h_sum, time_elapsed);\n",
        "\n",
        "    \n",
        "  int* d_data;\n",
        "  int* d_sum;\n",
        "  //allocate memory on device\n",
        "  checkCudaErr(cudaMalloc((void **)&d_data, N*sizeof(int)), \"cudaMalloc\");\n",
        "  checkCudaErr(cudaMalloc((void **)&d_sum, sizeof(int)), \"cudaMalloc\");\n",
        "\n",
        "  //copy device data to host memory\n",
        "  checkCudaErr(cudaMemcpy(d_data, h_data, N*sizeof(int), cudaMemcpyHostToDevice), \"cudaMemcpy D->H\");\n",
        "  \n",
        "  cudaEvent_t start_gpu, stop_gpu;\n",
        "  float time_elapsed_gpu;\n",
        "  cudaEventCreate(&start_gpu);\n",
        "  cudaEventRecord(start_gpu,0);\n",
        "  //call kernel  \n",
        "  InitData<<<1,1>>>(d_data, d_sum, N);\n",
        "\n",
        "  cudaEventCreate(&stop_gpu);\n",
        "  cudaEventRecord(stop_gpu,0);\n",
        "  cudaEventSynchronize(stop_gpu);\n",
        "\n",
        "  cudaEventElapsedTime(&time_elapsed_gpu, start_gpu, stop_gpu);\n",
        "\n",
        "  checkCudaErr(cudaDeviceSynchronize(), \"Syncronization\");\n",
        "  checkCudaErr(cudaGetLastError(), \"GPU Error\");\n",
        " \n",
        "  //copy device data to host memory\n",
        "  checkCudaErr(cudaMemcpy(h_data, d_data, N*sizeof(int), cudaMemcpyDeviceToHost), \"cudaMemcpy D->H\");\n",
        "  checkCudaErr(cudaMemcpy(&h_sum, d_sum, sizeof(int), cudaMemcpyDeviceToHost), \"cudaMemcpy D->H\");\n",
        "  \n",
        "  printf(\"Sum of the array computed in GPU is %d\\nTotal Time taken on GPU: %fs\\n\", h_sum, time_elapsed_gpu/1000);\n",
        "\n",
        "  //release GPU memory\n",
        "  cudaFree(d_data);\n",
        "  cudaFree(d_sum);\n",
        "  free(h_data);\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "2kD8lp-W-Y-T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7abd2687-a1af-4da2-c978-c73a2b1fed06"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/q2part1.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc /content/q2part1.cu -lcurand -o q2part1 && ./q2part1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2r--27GuyA3o",
        "outputId": "ced55dae-8e9f-4fa3-b4b3-0ef587aae9bb"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum of the array computed at CPU is 100\n",
            "Total Time taken on CPU: 0.000002s\n",
            "Sum of the array computed in GPU is 100\n",
            "Total Time taken on GPU: 0.000029s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/q2part1.cu\n",
        "#include <stdio.h>\n",
        "#include <bits/stdc++.h>\n",
        "\n",
        "inline cudaError_t checkCudaErr(cudaError_t err, const char* msg) {\n",
        "  if (err != cudaSuccess) {\n",
        "    fprintf(stderr, \"CUDA Runtime error at %s: %s\\n\", msg, cudaGetErrorString(err));\n",
        "  }\n",
        "  return err;\n",
        "}\n",
        " \n",
        "\n",
        "__global__ void InitData(int* data, int* d_sum, int N) \n",
        "{\n",
        "\n",
        "    // Since only one thread, threadIdx.x = 0, just use i = 0\n",
        "    for (int i=0;i<N;i++)\n",
        "      *d_sum+=data[i]; //Store sum\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  const int N = 100;  \n",
        "\n",
        "  int* h_data = (int*)calloc(N, sizeof(int));\n",
        "  for (int j=0;j<N;j++)\n",
        "    h_data[j]=1;\n",
        "  \n",
        "  clock_t start, end;\n",
        "  start = clock();\n",
        "  int h_sum = 0;\n",
        "  for (int j=0;j<N;j++)\n",
        "    h_sum+=h_data[j];\n",
        "  end = clock();\n",
        "  double time_elapsed = double(end - start) / double(CLOCKS_PER_SEC);\n",
        "  printf(\"Sum of the array computed at CPU is %d\\nTotal Time taken on CPU: %fs\\n\", h_sum, time_elapsed);\n",
        "\n",
        "    \n",
        "  int* d_data;\n",
        "  int* d_sum;\n",
        "  //allocate memory on device\n",
        "  checkCudaErr(cudaMalloc((void **)&d_data, N*sizeof(int)), \"cudaMalloc\");\n",
        "  checkCudaErr(cudaMalloc((void **)&d_sum, sizeof(int)), \"cudaMalloc\");\n",
        "\n",
        "  //copy device data to host memory\n",
        "  checkCudaErr(cudaMemcpy(d_data, h_data, N*sizeof(int), cudaMemcpyHostToDevice), \"cudaMemcpy D->H\");\n",
        "  \n",
        "  cudaEvent_t start_gpu, stop_gpu;\n",
        "  float time_elapsed_gpu;\n",
        "  cudaEventCreate(&start_gpu);\n",
        "  cudaEventRecord(start_gpu,0);\n",
        "  //call kernel  \n",
        "  InitData<<<1,10>>>(d_data, d_sum, N);\n",
        "\n",
        "  cudaEventCreate(&stop_gpu);\n",
        "  cudaEventRecord(stop_gpu,0);\n",
        "  cudaEventSynchronize(stop_gpu);\n",
        "\n",
        "  cudaEventElapsedTime(&time_elapsed_gpu, start_gpu, stop_gpu);\n",
        "\n",
        "  checkCudaErr(cudaDeviceSynchronize(), \"Syncronization\");\n",
        "  checkCudaErr(cudaGetLastError(), \"GPU Error\");\n",
        " \n",
        "  //copy device data to host memory\n",
        "  checkCudaErr(cudaMemcpy(h_data, d_data, N*sizeof(int), cudaMemcpyDeviceToHost), \"cudaMemcpy D->H\");\n",
        "  checkCudaErr(cudaMemcpy(&h_sum, d_sum, sizeof(int), cudaMemcpyDeviceToHost), \"cudaMemcpy D->H\");\n",
        "  \n",
        "  printf(\"Sum of the array computed in GPU is %d\\nTotal Time taken on GPU: %fs\\n\", h_sum, time_elapsed_gpu/1000);\n",
        "\n",
        "  //release GPU memory\n",
        "  cudaFree(d_data);\n",
        "  cudaFree(d_sum);\n",
        "  free(h_data);\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-18Ys7CP8Co1",
        "outputId": "dad3860e-2af6-44e5-ccb5-416080e9bcc8"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/q2part1.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc /content/q2part1.cu -lcurand -o q2part1 && ./q2part1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Snhn_YAL8IHp",
        "outputId": "89e8fcd9-8884-41e6-9bad-d15cc31a7e6c"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum of the array computed at CPU is 100\n",
            "Total Time taken on CPU: 0.000002s\n",
            "Sum of the array computed in GPU is 100\n",
            "Total Time taken on GPU: 0.000030s\n"
          ]
        }
      ]
    }
  ]
}